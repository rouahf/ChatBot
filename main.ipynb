{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Machine learning (ML) is the study of computer algorithms that improve automatically through experience.\n",
      "Machine learning algorithms are able to learn from data, identify patterns, and make predictions.\n",
      "Machine learning is a subfield of artificial intelligence (AI) that gives computers the ability to learn without being explicitly programmed.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, GoogleGenerativeAI\n",
    "\n",
    "# Configurez votre clé API Google Generative AI ici\n",
    "GOOGLE_API_KEY = 'AIzaSyAD35w9sxvo7DTnL85e0F5BsBsTH60g8xY'\n",
    "\n",
    "# Initialiser les embeddings et le modèle de langage Google Generative AI\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)\n",
    "llm = GoogleGenerativeAI(model=\"models/text-bison-001\", google_api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Supposons que la dimension des embeddings soit 768 (à ajuster selon votre modèle)\n",
    "EMBEDDING_DIM = 768\n",
    "\n",
    "# Classe pour gérer la mémoire du chatbot avec FAISS\n",
    "class ChatbotMemory:\n",
    "    def __init__(self, embeddings, embedding_dim):\n",
    "        self.embeddings = embeddings\n",
    "        self.index = faiss.IndexFlatIP(embedding_dim)\n",
    "        self.memory = {}\n",
    "\n",
    "    def remember(self, user_id, message):\n",
    "        if user_id not in self.memory:\n",
    "            self.memory[user_id] = []\n",
    "        self.memory[user_id].append(message)\n",
    "\n",
    "        # Obtenir l'embedding pour le message et l'indexer avec FAISS\n",
    "        embedding = self.embeddings.embed_query(message)\n",
    "        embedding = np.array([embedding]).astype('float32')  # FAISS nécessite des float32\n",
    "        self.index.add(embedding)\n",
    "\n",
    "    def recall(self, user_id, query, k=5):\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        query_embedding = np.array([query_embedding]).astype('float32')  # FAISS nécessite des float32\n",
    "        \n",
    "        # Rechercher les embeddings les plus similaires dans l'index FAISS\n",
    "        D, I = self.index.search(query_embedding, k)\n",
    "        \n",
    "        # Récupérer les messages correspondants aux indices I\n",
    "        similar_messages = [self.memory[user_id][i] for i in I[0] if i < len(self.memory[user_id])]\n",
    "        return similar_messages\n",
    "\n",
    "memory = ChatbotMemory(embeddings, EMBEDDING_DIM)\n",
    "\n",
    "# Exemple de fonction de chatbot avec recherche de similarité\n",
    "def chatbot(user_id, message):\n",
    "    memory.remember(user_id, message)\n",
    "    history = memory.recall(user_id, message)\n",
    "    \n",
    "    # Créer une invite de chat basée sur l'historique et le message actuel\n",
    "    prompt = f\"History: {' '.join(history)}\\nUser: {message}\"\n",
    "    \n",
    "    # Générer une réponse basée sur le contexte\n",
    "    response = llm.generate(prompts=[prompt])  # Notez que nous passons une liste de chaînes de caractères\n",
    "    \n",
    "    # Récupérer le texte généré à partir de LLMResult\n",
    "    generated_text = response.generations[0][0].text\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "# Exécuter le chatbot\n",
    "user_id = \"user123\"\n",
    "message = \"What is machine learning?\"\n",
    "response = chatbot(user_id, message)\n",
    "print(\"Chatbot:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
